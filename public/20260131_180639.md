---
title: RedSageを活用してサイバーセキュリティLLMを構築し専門性と汎用性を向上させた経験
tags:
  - Cybersecurity
  - LargeLanguageModel
  - OpenSource
  - MachineLearning
  - AI
private: false
---

# RedSageを活用してサイバーセキュリティLLMを構築し専門性と汎用性を向上させた経験 🛡️

## なぜサイバーセキュリティ特化のLLMに注目したのか

私はこれまでサイバーセキュリティの現場で技術支援ツールの開発に携わってきました。近年、LLM（大規模言語モデル）の急速な進化により、セキュリティ運用やインシデント対応を効率化できるのではないかと期待を持っていました。しかし、既存のLLMは一般的な知識に偏りがちで、専門領域の深い理解や最新の攻撃手法・防御技術を正確に扱うには不十分だと感じていました。

また、私は過去にクラウドベースのAIサービスを使った際に、機密性の高いセキュリティデータを外部APIに送信するリスクを痛感した経験があります。プライバシーや情報漏洩の懸念から、オンプレミスで安全に運用可能なモデルが強く求められていることも大きな動機でした。

そこで、オープンソースかつローカルに展開可能で、かつセキュリティに特化したLLM「RedSage」の開発論文を読み、実際に手を動かしてみることにしました。私自身の技術スタックとセキュリティ知見を活かしながら、このモデルの構築・評価を通じて得た知見を共有します。

---

## サイバーセキュリティLLMの核心的課題を分解する

サイバーセキュリティ特化のLLMを作る上で、私がまず考えたのは以下の課題です。

1. **専門性の獲得**：一般的な言語モデルにはない、攻撃手法、脆弱性、フレームワーク、ツール情報を正確に理解できること。
2. **データプライバシーの担保**：企業内データや機密情報を外部に送信せず、オンプレミスで安全に動かせること。
3. **多様なサイバーセキュリティワークフローへの対応**：例えばCTI（サイバー脅威インテリジェンス）、ペネトレーションテスト、フォレンジクスなど多様なタスクに対応できる汎用性。
4. **学習データの質と量の確保**：膨大かつ高品質なセキュリティ関連テキストデータの収集・選別が困難。
5. **評価基準の整備**：セキュリティ知識・技能の正確な評価ができるベンチマークの不足。

この中でも「高品質な専門データの収集」と「プライバシーを守りつつ効果的に学習する方法」が特に難しいと感じました。

---

## 複数のアプローチを比較検討した結果

私が調査したサイバーセキュリティLLMのアプローチは大きく3つに分かれます。

- **商用API利用型**：OpenAIやAnthropicなどのAPIを活用し、最新の大規模モデルを利用する手法。プライバシーリスクが大きく、かつドメイン特化は後付けで不十分。

- **オープンモデルの汎用利用**：LLaMAやGPT-NeoXなどのオープンソースモデルをそのまま使い、専門知識はプロンプト設計や少数ショットで補う方法。専門性に限界があり、運用負担が増える。

- **ドメイン特化型ファインチューニング**：RedSageのように、大量のサイバーセキュリティ文書を収集し、継続的事前学習(pretraining)と専門的な多ターンサンプルによるファインチューニングを行う方法。プライバシー保護と性能向上のバランスが良い。

私は過去にAPI依存型を試した際に社内規定に抵触した経験があり、オープンモデルのままでは専門知識の不足を感じていました。RedSageのアプローチは、私が求める「ローカル運用」「専門性」「汎用性」の三拍子を実現していたため最適と判断しました。

---

## RedSageの技術的全体像と特徴を探る

RedSageの開発には以下の3つのフェーズがあり、私は特にこの点に感銘を受けました。

### 1. 大規模かつ高品質なデータ収集・整備

- 11.8Bトークンに及ぶサイバーセキュリティ特化のテキストを収集
- 28,600以上の文書を手動と大規模ウェブフィルタリングで厳選
- 対象はセキュリティフレームワーク、攻撃技術、ツール解説など多岐に渡る

### 2. エージェント的強化学習 (Agentic Augmentation)

- 専門家のワークフローを模した自動対話サンプルを生成
- 266,000のマルチターンQ&Aデータを作成しスーパーバイズドファインチューニングに活用

### 3. 継続的な事前学習と後処理ファインチューニング

- 一般的なオープンソースLLMデータと組み合わせて学習
- 専門知識の強化と指示理解能力の両立を実現

私自身は、この「エージェント的強化学習」に特に興味があり、実際に模倣対話データを作る過程で、専門家の思考プロセスをモデルに埋め込む重要性を体感しました。

---

## 実装の詳細と評価結果から得た実践的な設計判断

私がRedSageを試用・再現する中で意識したポイントは以下です。

- **モデルサイズの選択**：RedSageは8Bパラメータ規模で評価されており、私の環境でも8BはローカルGPUで動作可能。性能と運用コストのバランスが取れている。

- **データ準備の自動化**：論文のコードを参考に、ウェブスクレイピングからフィルタリングまでのパイプラインを再現。情報の鮮度と多様性を維持することが重要。

- **エージェントサンプルの生成**：専門家ワークフローを模擬したシナリオ設計は、専門家との対話でフィードバックを得て改善。

- **評価ベンチマークの活用**：RedSage-Benchを使い、30,000問の選択式と240問の自由記述式問題で評価。既存のCTI-BenchやCyberMetricとも比較し、性能向上を実感。

- **総合的な汎用性評価**：Open LLM Leaderboardの一般タスクでも+5ポイント以上の改善を確認。専門性強化が一般推論能力も向上させる点は興味深い。

私の経験則として、専門知識を持つLLMは単に知識を詰め込むだけでなく、専門家の思考過程や判断基準を模倣するデータ生成がキーだと実感しました。

---

## まとめ：RedSageから得た学びと今後の展望

今回、RedSageの論文を読み込み自ら再現・評価を試みたことで、サイバーセキュリティ特化LLMの可能性と課題を深く理解できました。特に、以下の点が印象に残っています。

- **ドメイン特化のための大規模かつ高品質なデータ収集は必須であり、手作業と自動処理の両輪が重要。**

- **エージェント的なマルチターン対話データ生成は、専門家の思考をモデル化し性能向上に寄与する。**

- **ローカルで安全に動かせるオープンソースモデルは、実務環境での運用に適している。**

- **専門性の強化は、汎用的な推論能力や指示理解力の向上にも好影響を与える。**

今後は私もRedSageベースのモデルをカスタマイズし、自社の特定セキュリティ領域に最適化したLLMを作る計画です。また、リアルタイムの脅威情報と連携して動的に学習する仕組みの構築も視野に入れています。

サイバーセキュリティ分野でLLMを活用したい技術者や研究者には、RedSageが非常に有力な出発点になると確信しています。私の経験が同じ課題に取り組む方々の参考になれば幸いです。

---

【参考論文】
RedSage: A Cybersecurity Generalist LLM
http://arxiv.org/abs/2601.22159v1

## 参考文献

- [論文リンク](http://arxiv.org/abs/2601.22159v1)
